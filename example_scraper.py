#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Exemplo de uso do MarketRoxoScraper2 com bypass Cloudflare
"""

from scraper_2 import MarketRoxoScraper2
import json
import os
from dotenv import load_dotenv

def log_callback(message):
    """Fun√ß√£o de callback para logs"""
    print(f"[{time.strftime('%H:%M:%S')}] {message}")

def main():
    # Carrega vari√°veis de ambiente
    load_dotenv()
    
    # Configura√ß√µes atrav√©s de vari√°veis de ambiente
    base_url = os.getenv("MAIN_URL_SCRAPE_ROXO", "https://www.olx.com.br")
    
    # Configura√ß√£o do proxy (opcional)
    http_proxy = os.getenv("HTTP_PROXY", "")
    https_proxy = os.getenv("HTTPS_PROXY", "")
    proxy_config = http_proxy or https_proxy or ""
    
    # Palavras-chave para buscar
    keywords_str = os.getenv("DEFAULT_KEYWORDS", "bike,indoor,concept2,spinning,bicicleta,schwinn,technogym")
    keywords = [kw.strip() for kw in keywords_str.split(",") if kw.strip()]
    
    # Palavras-chave negativas (para filtrar)
    negative_keywords_str = os.getenv("NEGATIVE_KEYWORDS_LIST", "quebrada,defeito,pe√ßas,sucata")
    negative_keywords = [kw.strip() for kw in negative_keywords_str.split(",") if kw.strip()]
    
    # N√∫mero de p√°ginas para buscar
    max_pages = 2
    
    # Salvar p√°ginas para debug
    save_page = False
    
    # Inicializa o scraper
    scraper = MarketRoxoScraper2(
        log_callback=log_callback,
        base_url=base_url,
        proxies=proxy_config
    )
    
    try:
        # Executa o scraping
        print("üéØ Iniciando busca por an√∫ncios...")
        ads = scraper.scrape(
            keywords=keywords,
            negative_keywords_list=negative_keywords,
            max_pages=max_pages,
            save_page=save_page
        )
        
        # Exibe resultados
        print(f"\nüìä RESULTADO FINAL:")
        print(f"Total de an√∫ncios encontrados: {len(ads)}")
        
        if ads:
            print("\nüìã An√∫ncios encontrados:")
            for i, ad in enumerate(ads, 1):
                print(f"{i}. {ad['title']}")
                print(f"   URL: {ad['url']}")
                print()
            
            # Salva resultados em arquivo JSON
            output_file = os.getenv("OUTPUT_FILE", "anuncios_encontrados.json")
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(ads, f, ensure_ascii=False, indent=2)
            print(f"üíæ Resultados salvos em '{output_file}'")
        else:
            print("‚ùå Nenhum an√∫ncio encontrado com os crit√©rios especificados.")
            
    except Exception as e:
        print(f"üí• Erro durante o scraping: {e}")
        return False
    
    return True

if __name__ == "__main__":
    import time
    
    print("üöÄ MarketRoxo Scraper com Bypass Cloudflare")
    print("=" * 50)
    
    success = main()
    
    if success:
        print("\n‚úÖ Scraping conclu√≠do com sucesso!")
    else:
        print("\n‚ùå Scraping falhou!")