#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Exemplo de uso do MarketRoxoScraper2 com bypass Cloudflare
"""

from scraper_cloudflare import MarketRoxoScraperCloudflare
import json
import os
from dotenv import load_dotenv
import time
import random  # Import random for delay

def log_callback(message):
    """Fun√ß√£o de callback para logs"""
    print(f"[{time.strftime('%H:%M:%S')}] {message}")

def main():
    # Carrega vari√°veis de ambiente
    load_dotenv()
    
    # Configura√ß√µes atrav√©s de vari√°veis de ambiente
    base_url = os.getenv("MAIN_URL_SCRAPE_ROXO", "https://www.olx.com.br")
    
    # Configura√ß√£o do proxy (opcional)
    http_proxy = os.getenv("HTTP_PROXY", "")
    https_proxy = os.getenv("HTTPS_PROXY", "")
    proxy_config = http_proxy or https_proxy or ""
    use_proxy = True # Verifica se o proxy est√° configurado
    
    keywords_str = os.getenv("DEFAULT_KEYWORDS", "bike,indoor,concept2,spinning,bicicleta,schwinn,technogym")
    keywords = [kw.strip() for kw in keywords_str.split(",") if kw.strip()]

    # Palavras-chave negativas (para filtrar)
    negative_keywords_str = os.getenv("NEGATIVE_KEYWORDS_LIST", "quebrada,defeito,pe√ßas,sucata")
    negative_keywords = [kw.strip() for kw in negative_keywords_str.split(",") if kw.strip()]
    
    # N√∫mero de p√°ginas para buscar
    max_pages = 1
    
    # Salvar p√°ginas para debug
    save_page = False
    
    # Inicializa o scraper sem proxy se proxy_config estiver vazio
    if proxy_config and use_proxy:
        scraper = MarketRoxoScraperCloudflare(
            log_callback=log_callback,
            base_url=base_url,
            proxies=proxy_config
        )
    else:
        scraper = MarketRoxoScraperCloudflare(
            log_callback=log_callback,
            base_url=base_url
        )
    
    # Teste inicial de scrape err c/ marketroxo, repetindo at√© ter sucesso
    attempt = 0
    error_counts = {}
    error_messages = []  # Armazena mensagens √∫nicas de erro
    
    while True:
        try:
            attempt += 1
            print(f"üéØ Iniciando busca por an√∫ncios... Tentativa {attempt}")
            current_keywords_for_loop = keywords
            print(f"\nüîç Buscando an√∫ncios com as palavras-chave: {', '.join(current_keywords_for_loop)}")
            
            ads = scraper.scrape_err(
                query_keywords=current_keywords_for_loop, 
                keywords=current_keywords_for_loop,
                negative_keywords_list=negative_keywords,
                max_pages=max_pages,
                save_page=save_page
            )
            
            # Exibe resultados
            print(f"\nüìä RESULTADO FINAL:")
            print(f"Total de an√∫ncios encontrados: {len(ads)}")
            break  # Sai do loop em caso de sucesso
            
        except Exception as e:
            error_type = type(e).__name__
            error_message = str(e)
            error_counts[error_type] = error_counts.get(error_type, 0) + 1
            
            # Armazena uma representa√ß√£o √∫nica da mensagem de erro
            if f"{error_type}: {error_message}" not in error_messages:
                error_messages.append(f"{error_type}: {error_message}")
            
            print(f"üí• Erro durante o scraping (Tentativa {attempt}): {error_type} - {error_message}")
            print(f"Erros acumulados: {error_counts}")
            
            # Adiciona delay aleat√≥rio entre tentativas (entre 2 e 5 segundos)
            delay = random.uniform(3, 50)
            print(f"‚è≥ Aguardando {delay:.2f} segundos antes de tentar novamente...")
            time.sleep(delay)

    # --- Resumo dos Erros ---
    if error_counts:
        print("\n--- ERRO SUMMARY ---")
        for error_type, count in error_counts.items():
            print(f"Error Type: {error_type}, Occurrences: {count}")
        
        if error_messages:
            print("\nMessages:")
            for msg in error_messages:
                print(f"- {msg}")
    # --- Fim do Resumo dos Erros ---

    return True  # Indica que o processo de scraping terminou (com sucesso ou ap√≥s tentativas)

if __name__ == "__main__":
    
    print("üöÄ MarketRoxo Scraper com Bypass Cloudflare")
    print("=" * 50)
    
    success = main()
    
    if success:
        print("\n‚úÖ Scraping conclu√≠do com sucesso!")
    else:
        print("\n‚ùå Scraping falhou!")