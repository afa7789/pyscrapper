#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Exemplo de uso do MarketRoxoScraper2 com bypass Cloudflare
"""

from scraper_cloudflare import MarketRoxoScraperCloudflare
import json
import os
from dotenv import load_dotenv
import time  # Ensure time is imported for log_callback


def log_callback(message):
    """Fun√ß√£o de callback para logs"""
    print(f"[{time.strftime('%H:%M:%S')}] {message}")


def main():
    # Carrega vari√°veis de ambiente
    load_dotenv()

    # Configura√ß√µes atrav√©s de vari√°veis de ambiente
    base_url = os.getenv("MAIN_URL_SCRAPE_ROXO", "https://www.olx.com.br")

    # Configura√ß√£o do proxy (opcional)
    http_proxy = os.getenv("HTTP_PROXY", "")
    https_proxy = os.getenv("HTTPS_PROXY", "")
    # proxy_config = http_proxy or https_proxy or ""

    proxy_config = ""

    # Palavras-chave para buscar (tamb√©m usadas como query_keywords para a URL)
    keywords_str = "iphone,ipad,apple"
    keywords = [kw.strip() for kw in keywords_str.split(",") if kw.strip()]

    keywords_str2 = os.getenv(
        "DEFAULT_KEYWORDS", "bike,indoor,concept2,spinning,bicicleta,schwinn,technogym")
    keywords2 = [kw.strip() for kw in keywords_str2.split(",") if kw.strip()]

    array_of_keywords = [keywords, keywords2]

    # Palavras-chave negativas (para filtrar)
    negative_keywords_str = os.getenv(
        "NEGATIVE_KEYWORDS_LIST", "quebrada,defeito,pe√ßas,sucata")
    negative_keywords = [kw.strip()
                         for kw in negative_keywords_str.split(",") if kw.strip()]

    # N√∫mero de p√°ginas para buscar
    max_pages = 1

    # Salvar p√°ginas para debug
    save_page = False

    # Inicializa o scraper
    scraper = MarketRoxoScraperCloudflare(
        log_callback=log_callback,
        base_url=base_url,
        proxies=proxy_config
    )

    # def scrape_err(self, keywords, negative_keywords_list=None, query_keywords=None,
    #                start_page=1, num_pages_to_scrape=1, save_page=False,
    #                page_retry_attempts=3, page_retry_delay_min=5, page_retry_delay_max=15):
    # Teste inicial de scrape err c/ marketroxo,
    try:
        print("üéØ Iniciando busca por an√∫ncios...")
        for current_keywords_for_loop in array_of_keywords:  # Renamed loop variable for clarity
            print(
                f"\nüîç Buscando an√∫ncios com as palavras-chave: {', '.join(current_keywords_for_loop)}")

            ads = scraper.scrape_err(
                query_keywords=current_keywords_for_loop,
                keywords=current_keywords_for_loop,
                negative_keywords_list=negative_keywords,
                start_page=1,
                num_pages_to_scrape=max_pages,
                save_page=save_page,
                page_retry_attempts=10,
                page_retry_delay_min=30,
                page_retry_delay_max=67
            )

            # Exibe resultados
            print(f"\nüìä RESULTADO FINAL:")
            print(f"Total de an√∫ncios encontrados: {len(ads)}")

    except Exception as e:
        print(f"üí• Erro durante o scraping: {e}")
        return False

    return True


if __name__ == "__main__":

    print("üöÄ MarketRoxo Scraper com Bypass Cloudflare")
    print("=" * 50)

    success = main()

    if success:
        print("\n‚úÖ Scraping conclu√≠do com sucesso!")
    else:
        print("\n‚ùå Scraping falhou!")
